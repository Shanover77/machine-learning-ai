{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer # let's remove this @ujjawal\n",
    "from nltk.stem import WordNetLemmatizer # instead we will use lemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable SSL certificate verification\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "#### Data combining from different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/health_news_data.csv\n",
      "../data/technology_news_data.csv\n",
      "../data/politics_news_data.csv\n",
      "../data/sports_news_data.csv\n",
      "../data/business_news_data.csv\n",
      "../data/entertainment_news_data.csv\n",
      "../data/environment_news_data.csv\n",
      "../data/lifestyle_news_data.csv\n",
      "../data/programming_news_data.csv\n",
      "../data/education_news_data.csv\n",
      "\n",
      "Shape of the dataframe: (4448, 3)\n"
     ]
    }
   ],
   "source": [
    "# Following is the list of topics for which the medium data is available\n",
    "topic_list = [\n",
    "    \"health\",\n",
    "    \"technology\",\n",
    "    \"politics\",\n",
    "    \"sports\",\n",
    "    \"business\",\n",
    "    \"entertainment\",\n",
    "    \"environment\",\n",
    "    \"lifestyle\",\n",
    "    \"programming\",\n",
    "    \"education\",\n",
    "]\n",
    "\n",
    "# Create a empty dataframe\n",
    "df = pd.DataFrame(columns=[\"title\", \"topic\"])\n",
    "\n",
    "# Read the data from the csv files and store it in a dataframe\n",
    "for topic in topic_list:\n",
    "    csv_name = f\"../data/{topic}_news_data.csv\"\n",
    "    print(csv_name)\n",
    "    new_df = pd.read_csv(f\"{csv_name}\")\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "\n",
    "print(f\"\\nShape of the dataframe: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Exploration\n",
    "#### Initial understanding of the structure, content, and data types within a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I Asked Leading Covid Scientists — Off the Rec...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autopsy Findings of Vaccinated People (With Co...</td>\n",
       "      <td>health</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Latest Autopsy Study on mRNA Vaccine Recipient...</td>\n",
       "      <td>health</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From Infection to Recovery: How Long It Lasts</td>\n",
       "      <td>health</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Tough Covid Challenge: Reinforcing Our Wall ...</td>\n",
       "      <td>health</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   topic  Unnamed: 0\n",
       "0  I Asked Leading Covid Scientists — Off the Rec...  health         0.0\n",
       "1  Autopsy Findings of Vaccinated People (With Co...  health         1.0\n",
       "2  Latest Autopsy Study on mRNA Vaccine Recipient...  health         2.0\n",
       "3      From Infection to Recovery: How Long It Lasts  health         3.0\n",
       "4  A Tough Covid Challenge: Reinforcing Our Wall ...  health         4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using head() to display the first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I Asked Leading Covid Scientists — Off the Rec...</td>\n",
       "      <td>health</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autopsy Findings of Vaccinated People (With Co...</td>\n",
       "      <td>health</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Latest Autopsy Study on mRNA Vaccine Recipient...</td>\n",
       "      <td>health</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From Infection to Recovery: How Long It Lasts</td>\n",
       "      <td>health</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Tough Covid Challenge: Reinforcing Our Wall ...</td>\n",
       "      <td>health</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4443</th>\n",
       "      <td>“Balancing Act: How Students Can Deal with Stu...</td>\n",
       "      <td>education</td>\n",
       "      <td>404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4444</th>\n",
       "      <td>SCOTUS Likely To Negate Student Loan Forgivene...</td>\n",
       "      <td>education</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>I, The Ghost of a Woman Who Died in an 18th-Ce...</td>\n",
       "      <td>education</td>\n",
       "      <td>406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>The Latest Student Loan News: What Borrowers N...</td>\n",
       "      <td>education</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>Reducing College Costs with YIMBYism</td>\n",
       "      <td>education</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4448 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title      topic  Unnamed: 0\n",
       "0     I Asked Leading Covid Scientists — Off the Rec...     health         0.0\n",
       "1     Autopsy Findings of Vaccinated People (With Co...     health         1.0\n",
       "2     Latest Autopsy Study on mRNA Vaccine Recipient...     health         2.0\n",
       "3         From Infection to Recovery: How Long It Lasts     health         3.0\n",
       "4     A Tough Covid Challenge: Reinforcing Our Wall ...     health         4.0\n",
       "...                                                 ...        ...         ...\n",
       "4443  “Balancing Act: How Students Can Deal with Stu...  education       404.0\n",
       "4444  SCOTUS Likely To Negate Student Loan Forgivene...  education       405.0\n",
       "4445  I, The Ghost of a Woman Who Died in an 18th-Ce...  education       406.0\n",
       "4446  The Latest Student Loan News: What Borrowers N...  education       407.0\n",
       "4447               Reducing College Costs with YIMBYism  education       408.0\n",
       "\n",
       "[4448 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using tail() to display the last 5 rows of the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4448 entries, 0 to 4447\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   title       4448 non-null   object \n",
      " 1   topic       4448 non-null   object \n",
      " 2   Unnamed: 0  4448 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 104.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Using info() to display the information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          object\n",
       "topic          object\n",
       "Unnamed: 0    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using dtypes to display the data types of the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'topic', 'Unnamed: 0'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using columns to display the columns of the dataset\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows with no values (\"Unnamed: 0\")\n",
    "# Specify the columns to remove\n",
    "columns_to_remove = [\"Unnamed: 0\"]\n",
    "\n",
    "# Remove the specified columns\n",
    "df = df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Duplicates\n",
    "#### Identify and remove duplicate rows if they exist in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset before handling duplicates:  (4448, 2)\n",
      "Shape of the dataset after handling duplicates:  (4245, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check Shape of the dataset before handling duplicates\n",
    "print(\"Shape of the dataset before handling duplicates: \", df.shape)\n",
    "\n",
    "# Drop duplicate rows if there is any duplicate row\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Check Shape of the dataset after handling duplicates\n",
    "print(\"Shape of the dataset after handling duplicates: \", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "#### Identify missing values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "topic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check If Imbalanced Classes\n",
    "#### We try to categorize title data with topic so let's see if there is imbalance data or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic\n",
       "health           546\n",
       "business         527\n",
       "technology       510\n",
       "sports           478\n",
       "programming      455\n",
       "education        408\n",
       "environment      401\n",
       "politics         378\n",
       "entertainment    273\n",
       "lifestyle        269\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows according to unique topics\n",
    "df[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shanover\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Perform text preprocessing\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to perform text preprocessing\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    # Remove punctuations and special characters using regex and string module\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    text = re.sub(r\"[\\–\\—]\", \"\", text)  # Remove special characters like dashes\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove punctuation and special chars\n",
    "    text = remove_punctuations(text)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    #stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    lemmatized_tokens = []\n",
    "    \n",
    "    # Apply lemma\n",
    "    for token, pos_tag in nltk.pos_tag(tokens):\n",
    "        # Map POS tag to WordNet tag\n",
    "        wn_tag = nltk.corpus.wordnet.NOUN\n",
    "        if pos_tag.startswith('J'):\n",
    "            wn_tag = nltk.corpus.wordnet.ADJ\n",
    "        elif pos_tag.startswith('V'):\n",
    "            wn_tag = nltk.corpus.wordnet.VERB\n",
    "        elif pos_tag.startswith('R'):\n",
    "            wn_tag = nltk.corpus.wordnet.ADV\n",
    "        # Lemmatize token\n",
    "        lemmatized_token = lemmatizer.lemmatize(token, pos=wn_tag)\n",
    "        lemmatized_tokens.append(lemmatized_token)\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "      <th>preprocessed_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I Asked Leading Covid Scientists — Off the Rec...</td>\n",
       "      <td>health</td>\n",
       "      <td>ask lead covid scientist record virus ’ origin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Autopsy Findings of Vaccinated People (With Co...</td>\n",
       "      <td>health</td>\n",
       "      <td>autopsy finding vaccinate people covid vaccine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Latest Autopsy Study on mRNA Vaccine Recipient...</td>\n",
       "      <td>health</td>\n",
       "      <td>late autopsy study mrna vaccine recipient germ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From Infection to Recovery: How Long It Lasts</td>\n",
       "      <td>health</td>\n",
       "      <td>infection recovery long last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Tough Covid Challenge: Reinforcing Our Wall ...</td>\n",
       "      <td>health</td>\n",
       "      <td>tough covid challenge reinforce wall immunity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   topic   \n",
       "0  I Asked Leading Covid Scientists — Off the Rec...  health  \\\n",
       "1  Autopsy Findings of Vaccinated People (With Co...  health   \n",
       "2  Latest Autopsy Study on mRNA Vaccine Recipient...  health   \n",
       "3      From Infection to Recovery: How Long It Lasts  health   \n",
       "4  A Tough Covid Challenge: Reinforcing Our Wall ...  health   \n",
       "\n",
       "                                  preprocessed_title  \n",
       "0  ask lead covid scientist record virus ’ origin...  \n",
       "1  autopsy finding vaccinate people covid vaccine...  \n",
       "2  late autopsy study mrna vaccine recipient germ...  \n",
       "3                       infection recovery long last  \n",
       "4      tough covid challenge reinforce wall immunity  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply text preprocessing to the 'title' column\n",
    "df[\"preprocessed_title\"] = df[\"title\"].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the preprocessed text (features) and the corresponding topics (labels)\n",
    "X = df[\"preprocessed_title\"]\n",
    "y = df[\"topic\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the preprocessed text into numerical representations using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SVM model\n",
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5535924617196702\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at ../models\\svc_title_to_category_55.joblib\n"
     ]
    }
   ],
   "source": [
    "## Saving the model\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Assuming you have trained and obtained your model\n",
    "\n",
    "# Specify the directory path for saving models\n",
    "models_dir = '..\\models'\n",
    "\n",
    "def saveModel(models_dir, filename, model):\n",
    "\n",
    "    # Create the models directory if it doesn't exist\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "    # Specify the file path for saving the model\n",
    "    model_path = os.path.join(models_dir, filename + '.joblib')\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(model, model_path)\n",
    "\n",
    "    print(f\"Model saved successfully at {model_path}\")\n",
    "    \n",
    "\n",
    "# Saving SVC model:\n",
    "saveModel('../models','svc_title_to_category_55', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.5594817432273262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize individual models\n",
    "svc = SVC()\n",
    "nb = MultinomialNB()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define the voting classifier with the individual models\n",
    "voting_classifier = VotingClassifier(estimators=[('svc', svc), ('nb', nb), ('rf', rf)])\n",
    "\n",
    "# Train the voting classifier\n",
    "voting_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set using the ensemble model\n",
    "ensemble_predictions = voting_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(\"Ensemble Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully at ../models\\ensemble_title2category_56.joblib\n"
     ]
    }
   ],
   "source": [
    "# Save ensemble model\n",
    "saveModel('../models','ensemble_title2category_56', voting_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A bit more better accuracy achieved using Ensemble voting: 56.18%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sequential NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "107/107 [==============================] - 2s 11ms/step - loss: 2.2233 - accuracy: 0.2491\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 1.4580 - accuracy: 0.6246\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 0.6066 - accuracy: 0.8645\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 0.2814 - accuracy: 0.9258\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 0.1848 - accuracy: 0.9420\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 0.1362 - accuracy: 0.9499\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 0.1206 - accuracy: 0.9508\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 1s 11ms/step - loss: 0.1108 - accuracy: 0.9544\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.1068 - accuracy: 0.9511\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 1s 10ms/step - loss: 0.1011 - accuracy: 0.9514\n",
      "27/27 [==============================] - 0s 2ms/step\n",
      "Neural Network Accuracy: 0.5394581861012956\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume you have your TF-IDF encoded features in X and corresponding labels in y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit vectorizer and transform training data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train).toarray()\n",
    "\n",
    "# Transform test data using the fitted vectorizer\n",
    "X_test_tfidf = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(X_train_tfidf.shape[1],), activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train_encoded, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Decode predictions\n",
    "y_pred = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Neural Network Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remark:\n",
    "\n",
    "#### After using NN, the accuracy didn't improved. There seems to be an issue in the pred_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_test = y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [27], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get the unique value counts as a Pandas Series\u001b[39;00m\n\u001b[0;32m      5\u001b[0m series_pred \u001b[38;5;241m=\u001b[39m series\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m----> 6\u001b[0m \u001b[43mvalue_counts\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'value_counts' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert the NumPy array to a Pandas Series\n",
    "series = pd.Series(y_pred)\n",
    "\n",
    "# Get the unique value counts as a Pandas Series\n",
    "series_pred = series.value_counts()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the distribution between test_y, pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               self  other\n",
      "business        107    117\n",
      "education        82     73\n",
      "entertainment    60     65\n",
      "environment      57     73\n",
      "health          130    120\n",
      "lifestyle        43     39\n",
      "politics         83     87\n",
      "programming      78     93\n",
      "sports          102     86\n",
      "technology      107     96\n"
     ]
    }
   ],
   "source": [
    "# Align the labels of the two Series\n",
    "series1, series2 = series_test.align(series_pred, fill_value=0)\n",
    "\n",
    "# Compare the two aligned Series\n",
    "comparison = series1.compare(series2)\n",
    "\n",
    "# Print the comparison result\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running SVC Model on new news-titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess new titles\n",
    "new_titles = [\n",
    "    \"Cancer drug found after using AI\",\n",
    "    \"Is this the end of coding? AI Rules over restaurant jobs\",\n",
    "]\n",
    "new_titles_preprocessed = [preprocess_text(title) for title in new_titles]\n",
    "\n",
    "# Convert the preprocessed titles into numerical representations\n",
    "new_titles_tfidf = vectorizer.transform(new_titles_preprocessed)\n",
    "\n",
    "# Predict the topics of the new titles\n",
    "new_titles_predictions = model.predict(new_titles_tfidf)\n",
    "print(\"New Titles Predictions:\", new_titles_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Ensemble Voting Classifier on new news-titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_titles = [\n",
    "    \"Critiano scores a hattrick\",\n",
    "    \"Is this the end of coding? AI Rules over restaurant jobs\",\n",
    "]\n",
    "new_titles_preprocessed = [preprocess_text(title) for title in new_titles]\n",
    "\n",
    "# Convert the preprocessed titles into numerical representations\n",
    "new_titles_tfidf = vectorizer.transform(new_titles_preprocessed)\n",
    "\n",
    "# Predict the topics of the new titles\n",
    "new_titles_predictions = voting_classifier.predict(new_titles_tfidf)\n",
    "print(\"New Titles Predictions:\", new_titles_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Topic modeling,\n",
    "CLustering\n",
    "LDA, NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
